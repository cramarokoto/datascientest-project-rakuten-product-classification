{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2f05b0e",
   "metadata": {},
   "source": [
    "# Chargement des données et séparation des features et target\n",
    "\n",
    "Avant tout préprocessing, on établit la séparation des données de train et de test afin de limiter la possibilité de data leak entre les jeux de données de train et de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5a3203f-51c9-4a8e-884b-a3f51c249559",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "X_train = pd.read_csv(\"../data/X_train_update.csv\", index_col = 0)\n",
    "y_train = pd.read_csv(\"../data/Y_train_CVw08PX.csv\", index_col = 0)\n",
    "X_test = pd.read_csv(\"../data/X_test_update.csv\", index_col = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc74c90f",
   "metadata": {},
   "source": [
    "# Preprocessing des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7524fbbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /home/cramarokoto/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import hstack\n",
    "\n",
    "# Traitement des variables textuelles\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "nltk.download('punkt_tab')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import FrenchStemmer\n",
    "\n",
    "# Stopwords\n",
    "\n",
    "html_stopwords = [\n",
    "    'html', 'head', 'body', 'div', 'span', 'p', 'br', 'a', 'img', 'ul', 'li', 'ol', 'table',\n",
    "    'tr', 'td', 'th', 'h1', 'h2', 'h3', 'h4', 'h5', 'h6', 'b', 'i', 'u', 'strong', 'em',\n",
    "    'eacute', 'agrave'\n",
    "]\n",
    "punctuation_words = [\",\", \".\", \"``\", \"@\", \"*\", \"(\", \")\", \"...\", \"!\", \"?\", \"-\", \n",
    "                  \"_\", \">\", \"<\", \":\", \"/\", \"=\", \"--\", \"©\", \"~\", \";\", \"\\\\\", \"\\\\\\\\\"]\n",
    "final_stopwords = stopwords.words('english') + stopwords.words('french') + html_stopwords + punctuation_words\n",
    "\n",
    "\n",
    "# Stemming and processing\n",
    "\n",
    "stemmer = FrenchStemmer()\n",
    "\n",
    "def stemming(mots) :\n",
    "    sortie = []\n",
    "    for string in mots :\n",
    "        radical = stemmer.stem(string)\n",
    "        if (radical not in sortie) : sortie.append(radical)\n",
    "    return sortie\n",
    "\n",
    "\n",
    "def preprocessing(text, with_stemming=False):\n",
    "    text = text.lower()\n",
    "    tokens = word_tokenize(text)\n",
    "    result = [word for word in tokens if word not in final_stopwords]\n",
    "    if with_stemming:\n",
    "        result = stemming(result)\n",
    "    return ' '.join(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f056de9",
   "metadata": {},
   "source": [
    "## Preprocessing des données textuelles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71574319",
   "metadata": {},
   "source": [
    "### Création de la variable `has_description` basée sur la présence de la variable `description`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae68799",
   "metadata": {},
   "source": [
    "Nous avons vu lors de l'exploration que la répartition de la présence de description n'est pas homogène parmi les catégories de produits. On peut en déduire que l'absence ou présence de description est une information à part entière qu'il peut être intéressant d'exploiter dans nos modèles.\n",
    "\n",
    "Nous décidons de créer la variable `has_description` qui vaut :\n",
    "- 1 si la description est présente\n",
    "- 0 sinon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2f2ca5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pour X_train\n",
    "X_train['has_description'] = X_train['description'].notnull() & (X_train['description'].str.strip() != \"\")\n",
    "X_train['has_description'] = X_train['has_description'].astype(int)\n",
    "\n",
    "# Pour X_test\n",
    "X_test['has_description'] = X_test['description'].notnull() & (X_test['description'].str.strip() != \"\")\n",
    "X_test['has_description'] = X_test['has_description'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a14bf2e",
   "metadata": {},
   "source": [
    "### Fusion des variables `designation` et `description` dans `full_description`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4037be98",
   "metadata": {},
   "source": [
    "La `description` et la `designation` sont toutes les deux des valeurs textuelles libres. Bien que `designation` soit plus courte, elles apportent le même type d'information sur le produit c'est-à-dire sa description et son appellation commune. `description` pouvant être nulle, cela peut être gênant pour son intégration dans les modèles. \n",
    "\n",
    "Afin de faciliter le traitement de ces deux valeurs textuelles, nous décidons de les fusionner dans une variable nommée `full_description`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16942616",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pour X_train\n",
    "X_train['full_description'] = (\n",
    "    X_train['designation'] + \" \" + X_train['description'].fillna('')\n",
    ").str.strip()\n",
    "# Nettoyage des colonnes inutiles\n",
    "X_train = X_train.drop(columns=['designation', 'description'])\n",
    "\n",
    "# Pour X_test\n",
    "X_test['full_description'] = (\n",
    "    X_test['designation'] + \" \" + X_test['description'].fillna('')\n",
    ").str.strip()\n",
    "# Nettoyage des colonnes inutiles\n",
    "X_test = X_test.drop(columns=['designation', 'description'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3693a70",
   "metadata": {},
   "source": [
    "### Nettoyage, tokenisation et stemmatisation de la variable `full_description`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "308eb1cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preprocessed_full_description</th>\n",
       "      <th>full_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>olivi personalisiert notizbuch 150 seiten punk...</td>\n",
       "      <td>Olivia: Personalisiertes Notizbuch / 150 Seite...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>journal art n° 133 28/09/2001 l'art march salo...</td>\n",
       "      <td>Journal Des Arts (Le) N° 133 Du 28/09/2001 - L...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>grand stylet ergonom bleu gamepad nintendo wii...</td>\n",
       "      <td>Grand Stylet Ergonomique Bleu Gamepad Nintendo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>peluch donald europ disneyland 2000 marionnet ...</td>\n",
       "      <td>Peluche Donald - Europe - Disneyland 2000 (Mar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>guerr tuqu luc id &amp; grandeur veut organis jeu ...</td>\n",
       "      <td>La Guerre Des Tuques Luc a des id&amp;eacute;es de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>afriqu contemporain n° 212 hiv 2004 dossi japon</td>\n",
       "      <td>Afrique Contemporaine N° 212 Hiver 2004 - Doss...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>christof e bildungsprozessen auf der spur</td>\n",
       "      <td>Christof E: Bildungsprozessen Auf Der Spur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>conquer sept cahi couvertur polypro 240 x 320 ...</td>\n",
       "      <td>Conquérant Sept Cahier Couverture Polypro 240 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>puzzl scooby-doo post 2x35 piec</td>\n",
       "      <td>Puzzle Scooby-Doo Avec Poster 2x35 Pieces</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>tent pli v3s5-pro pvc blanc 3 x 4m50 longueur ...</td>\n",
       "      <td>Tente Pliante V3s5-Pro Pvc Blanc - 3 X 4m50 - ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       preprocessed_full_description  \\\n",
       "0  olivi personalisiert notizbuch 150 seiten punk...   \n",
       "1  journal art n° 133 28/09/2001 l'art march salo...   \n",
       "2  grand stylet ergonom bleu gamepad nintendo wii...   \n",
       "3  peluch donald europ disneyland 2000 marionnet ...   \n",
       "4  guerr tuqu luc id & grandeur veut organis jeu ...   \n",
       "5    afriqu contemporain n° 212 hiv 2004 dossi japon   \n",
       "6          christof e bildungsprozessen auf der spur   \n",
       "7  conquer sept cahi couvertur polypro 240 x 320 ...   \n",
       "8                    puzzl scooby-doo post 2x35 piec   \n",
       "9  tent pli v3s5-pro pvc blanc 3 x 4m50 longueur ...   \n",
       "\n",
       "                                    full_description  \n",
       "0  Olivia: Personalisiertes Notizbuch / 150 Seite...  \n",
       "1  Journal Des Arts (Le) N° 133 Du 28/09/2001 - L...  \n",
       "2  Grand Stylet Ergonomique Bleu Gamepad Nintendo...  \n",
       "3  Peluche Donald - Europe - Disneyland 2000 (Mar...  \n",
       "4  La Guerre Des Tuques Luc a des id&eacute;es de...  \n",
       "5  Afrique Contemporaine N° 212 Hiver 2004 - Doss...  \n",
       "6         Christof E: Bildungsprozessen Auf Der Spur  \n",
       "7  Conquérant Sept Cahier Couverture Polypro 240 ...  \n",
       "8          Puzzle Scooby-Doo Avec Poster 2x35 Pieces  \n",
       "9  Tente Pliante V3s5-Pro Pvc Blanc - 3 X 4m50 - ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = pd.DataFrame(columns=['preprocessed_full_description', 'full_description'])\n",
    "\n",
    "for i in range(0, 10):\n",
    "    current_description = X_train.loc[i, 'full_description']\n",
    "    result.loc[i, 'full_description'] = current_description\n",
    "    result.loc[i, 'preprocessed_full_description'] = preprocessing(current_description, with_stemming=True)\n",
    "\n",
    "display(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c22d57",
   "metadata": {},
   "source": [
    "On note avec l'extrait ci-dessus que la stemmatisation est trop violente sur le contenu de la variable d'une part et qu'il n'est pas adapté sur un contenu multilingue tel que nous avons ici (français, anglais mais aussi parfois allemand). Afin de limiter la perte en information, nous décidons de ne pas appliquer de lemmatisation ni de stemmatisation.\n",
    "\n",
    "Il aurait aussi été possible de traduire les textes pour uniformiser la langue employée mais cela représente :\n",
    "- un traitement coûteux\n",
    "- un risque de perte d'information si la traduction n'est pas de bonne qualité\n",
    "\n",
    "Comme le jeu de données est conséquent, on peut s'attendre à ce que les algorithme d'analyse textuel arrivent à extraire l'information utile malgré la présence de multiple langues.\n",
    "\n",
    "On décide donc de limiter le prétraitement textuel aux éléments suivants :\n",
    "- nettoyage des stopwords anglais et français\n",
    "- nettoyage de la ponctuation\n",
    "- tokenisation des chaînes de caractères"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4cee8ce0-221c-4046-b468-53c167a1f794",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['preprocessed_full_description'] = \"\"\n",
    "X_test['preprocessed_full_description'] = \"\"\n",
    "\n",
    "for i in X_train.index:\n",
    "    X_train.loc[i, 'preprocessed_full_description'] = preprocessing(X_train.loc[i, 'full_description'])\n",
    "\n",
    "for i in X_test.index:\n",
    "    X_test.loc[i, 'preprocessed_full_description'] = preprocessing(X_test.loc[i, 'full_description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "921f4adf-4ff4-4b93-8225-12c341e41d24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_description</th>\n",
       "      <th>preprocessed_full_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Olivia: Personalisiertes Notizbuch / 150 Seite...</td>\n",
       "      <td>olivia personalisiertes notizbuch 150 seiten p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Journal Des Arts (Le) N° 133 Du 28/09/2001 - L...</td>\n",
       "      <td>journal arts n° 133 28/09/2001 l'art marche sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Grand Stylet Ergonomique Bleu Gamepad Nintendo...</td>\n",
       "      <td>grand stylet ergonomique bleu gamepad nintendo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Peluche Donald - Europe - Disneyland 2000 (Mar...</td>\n",
       "      <td>peluche donald europe disneyland 2000 marionne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>La Guerre Des Tuques Luc a des id&amp;eacute;es de...</td>\n",
       "      <td>guerre tuques luc id &amp; grandeur veut organiser...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Afrique Contemporaine N° 212 Hiver 2004 - Doss...</td>\n",
       "      <td>afrique contemporaine n° 212 hiver 2004 dossie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Christof E: Bildungsprozessen Auf Der Spur</td>\n",
       "      <td>christof e bildungsprozessen auf der spur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Conquérant Sept Cahier Couverture Polypro 240 ...</td>\n",
       "      <td>conquérant sept cahier couverture polypro 240 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Puzzle Scooby-Doo Avec Poster 2x35 Pieces</td>\n",
       "      <td>puzzle scooby-doo poster 2x35 pieces</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Tente Pliante V3s5-Pro Pvc Blanc - 3 X 4m50 - ...</td>\n",
       "      <td>tente pliante v3s5-pro pvc blanc 3 x 4m50 long...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    full_description  \\\n",
       "0  Olivia: Personalisiertes Notizbuch / 150 Seite...   \n",
       "1  Journal Des Arts (Le) N° 133 Du 28/09/2001 - L...   \n",
       "2  Grand Stylet Ergonomique Bleu Gamepad Nintendo...   \n",
       "3  Peluche Donald - Europe - Disneyland 2000 (Mar...   \n",
       "4  La Guerre Des Tuques Luc a des id&eacute;es de...   \n",
       "5  Afrique Contemporaine N° 212 Hiver 2004 - Doss...   \n",
       "6         Christof E: Bildungsprozessen Auf Der Spur   \n",
       "7  Conquérant Sept Cahier Couverture Polypro 240 ...   \n",
       "8          Puzzle Scooby-Doo Avec Poster 2x35 Pieces   \n",
       "9  Tente Pliante V3s5-Pro Pvc Blanc - 3 X 4m50 - ...   \n",
       "\n",
       "                       preprocessed_full_description  \n",
       "0  olivia personalisiertes notizbuch 150 seiten p...  \n",
       "1  journal arts n° 133 28/09/2001 l'art marche sa...  \n",
       "2  grand stylet ergonomique bleu gamepad nintendo...  \n",
       "3  peluche donald europe disneyland 2000 marionne...  \n",
       "4  guerre tuques luc id & grandeur veut organiser...  \n",
       "5  afrique contemporaine n° 212 hiver 2004 dossie...  \n",
       "6          christof e bildungsprozessen auf der spur  \n",
       "7  conquérant sept cahier couverture polypro 240 ...  \n",
       "8               puzzle scooby-doo poster 2x35 pieces  \n",
       "9  tente pliante v3s5-pro pvc blanc 3 x 4m50 long...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_description</th>\n",
       "      <th>preprocessed_full_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>84916</th>\n",
       "      <td>Folkmanis Puppets - 2732 - Marionnette Et Théâ...</td>\n",
       "      <td>folkmanis puppets 2732 marionnette théâtre min...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84917</th>\n",
       "      <td>Porte Flamme Gaxix - Flamebringer Gaxix - 136/...</td>\n",
       "      <td>porte flamme gaxix flamebringer gaxix 136/220 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84918</th>\n",
       "      <td>Pompe de filtration Speck Badu 95</td>\n",
       "      <td>pompe filtration speck badu 95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84919</th>\n",
       "      <td>Robot de piscine électrique &lt;p&gt;Ce robot de pis...</td>\n",
       "      <td>robot piscine électrique robot piscine &amp; # 39 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84920</th>\n",
       "      <td>Hsm Destructeur Securio C16 Coupe Crois¿E: 4 X...</td>\n",
       "      <td>hsm destructeur securio c16 coupe crois¿e 4 x ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84921</th>\n",
       "      <td>Cadre Universal Pro Mont Accessoires Pour Dji ...</td>\n",
       "      <td>cadre universal pro mont accessoires dji osmo ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84922</th>\n",
       "      <td>5 Biberons Roses En Pâte À Sucre Lot de 5 bibe...</td>\n",
       "      <td>5 biberons roses pâte sucre lot 5 biberons 3cm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84923</th>\n",
       "      <td>Maigrir Rester Jeune N°1 Octobre 1974</td>\n",
       "      <td>maigrir rester jeune n°1 octobre 1974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84924</th>\n",
       "      <td>Grand Canapé 3 Places Chesterfield Blanc Le vé...</td>\n",
       "      <td>grand canapé 3 places chesterfield blanc vérit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84925</th>\n",
       "      <td>Piscine Beach Wave 229x229x56 cm 57495NP &lt;p&gt;Ce...</td>\n",
       "      <td>piscine beach wave 229x229x56 cm 57495np cette...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        full_description  \\\n",
       "84916  Folkmanis Puppets - 2732 - Marionnette Et Théâ...   \n",
       "84917  Porte Flamme Gaxix - Flamebringer Gaxix - 136/...   \n",
       "84918                  Pompe de filtration Speck Badu 95   \n",
       "84919  Robot de piscine électrique <p>Ce robot de pis...   \n",
       "84920  Hsm Destructeur Securio C16 Coupe Crois¿E: 4 X...   \n",
       "84921  Cadre Universal Pro Mont Accessoires Pour Dji ...   \n",
       "84922  5 Biberons Roses En Pâte À Sucre Lot de 5 bibe...   \n",
       "84923              Maigrir Rester Jeune N°1 Octobre 1974   \n",
       "84924  Grand Canapé 3 Places Chesterfield Blanc Le vé...   \n",
       "84925  Piscine Beach Wave 229x229x56 cm 57495NP <p>Ce...   \n",
       "\n",
       "                           preprocessed_full_description  \n",
       "84916  folkmanis puppets 2732 marionnette théâtre min...  \n",
       "84917  porte flamme gaxix flamebringer gaxix 136/220 ...  \n",
       "84918                     pompe filtration speck badu 95  \n",
       "84919  robot piscine électrique robot piscine & # 39 ...  \n",
       "84920  hsm destructeur securio c16 coupe crois¿e 4 x ...  \n",
       "84921  cadre universal pro mont accessoires dji osmo ...  \n",
       "84922  5 biberons roses pâte sucre lot 5 biberons 3cm...  \n",
       "84923              maigrir rester jeune n°1 octobre 1974  \n",
       "84924  grand canapé 3 places chesterfield blanc vérit...  \n",
       "84925  piscine beach wave 229x229x56 cm 57495np cette...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(X_train[[\"full_description\", \"preprocessed_full_description\"]].head(10))\n",
    "display(X_test[[\"full_description\", \"preprocessed_full_description\"]].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31dfce9e",
   "metadata": {},
   "source": [
    "### Application de TF-IDF à la variable `full_description`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b305bb9d",
   "metadata": {},
   "source": [
    "En l'état, les chaînes de caractères dans full_description sont difficilement exploitables par des algorithmes de machine learning.\n",
    "\n",
    "Il est nécessaire de les transformer en valeurs numériques interprétables. Nous avons décidé d'appliquer le TF-IDF pour une extraction de donnée rapide et efficace suite à notre analyse en wordcloud qui fait apparaître la répétition de mots clés pour chaque catégorie de produits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b28f85c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialisation du vecteur TF-IDF\n",
    "tfidf = TfidfVectorizer(\n",
    "    max_features=10000,\n",
    "    ngram_range=(1,2)\n",
    ")\n",
    "\n",
    "# Apprentissage sur X_train et transformation\n",
    "X_train_tfidf = tfidf.fit_transform(X_train['preprocessed_full_description'])\n",
    "X_test_tfidf = tfidf.transform(X_test['preprocessed_full_description'])\n",
    "\n",
    "# Suppression des colones temporaires\n",
    "X_train = X_train.drop(columns=['preprocessed_full_description', 'full_description'])\n",
    "X_test = X_test.drop(columns=['preprocessed_full_description', 'full_description'])\n",
    "\n",
    "# Concaténation\n",
    "X_train_final = hstack([X_train, X_train_tfidf])\n",
    "X_test_final = hstack([X_test, X_test_tfidf])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c65cc41",
   "metadata": {},
   "source": [
    "### Sauvegarde des données textuelles suite à leur préprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a2d00a",
   "metadata": {},
   "source": [
    "Afin de faciliter le travail sur plusieurs modèles et gagner du temps, on décide de sauvegarder les données prétraitées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bcb6270a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarde des données prétraitées dans des fichiers CSV\n",
    "\n",
    "X_train.to_csv(\"../data/preprocessed/X_train_preprocessed.csv\")\n",
    "X_test.to_csv(\"../data/preprocessed/X_test_preprocessed.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16796cb2",
   "metadata": {},
   "source": [
    "## Preprocessing des données graphiques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fec2c7e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8198fca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
