{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96ac5aa3-206d-4fda-b007-2dac4a203eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\Cansu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Libraries \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Text Processing:\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt_tab')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.stem.snowball import FrenchStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5a3203f-51c9-4a8e-884b-a3f51c249559",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement des données\n",
    "\n",
    "X_train = pd.read_csv(\"../data/X_train_update.csv\", index_col = 0)\n",
    "y_train = pd.read_csv(\"../data/Y_train_CVw08PX.csv\", index_col = 0)\n",
    "X_test = pd.read_csv(\"../data/X_test_update.csv\", index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f6ddef2-5340-435f-a5e3-5891969f238b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stopwords\n",
    "\n",
    "html_stopwords = ['br', 'p', 'div', 'span', 'b', 'i', 'li', 'ul', 'strong', 'em']\n",
    "new_stop_words = [\",\", \".\", \"``\", \"@\", \"*\", \"(\", \")\", \"...\", \"!\", \"?\", \"-\", \n",
    "                  \"_\", \">\", \"<\", \":\", \"/\", \"=\", \"--\", \"©\", \"~\", \";\", \"\\\\\", \"\\\\\\\\\"]\n",
    "final_stopwords = stopwords.words('english') + stopwords.words('french') + html_stopwords + new_stop_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d9ce49a-c7bb-434c-ac53-b5e6e6a91653",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stemming and processing\n",
    "\n",
    "stemmer = FrenchStemmer()\n",
    "\n",
    "def stemming(mots) :\n",
    "    sortie = []\n",
    "    for string in mots :\n",
    "        radical = stemmer.stem(string)\n",
    "        if (radical not in sortie) : sortie.append(radical)\n",
    "    return sortie\n",
    "\n",
    "\n",
    "def preprocessing(text):\n",
    "    text = text.lower()\n",
    "    tokens = word_tokenize(text)\n",
    "    stop_removed = [word for word in tokens if word not in final_stopwords]\n",
    "    stemmed = stemming(stop_removed)\n",
    "    return ' '.join(stemmed)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4cee8ce0-221c-4046-b468-53c167a1f794",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stemmed variable:\n",
    "\n",
    "X_train['preprocessed_designation'] = \"\"\n",
    "\n",
    "for i in range(0, len(X_train)):\n",
    "    X_train.loc[i, 'preprocessed_designation'] = preprocessing(X_train.loc[i, 'designation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "921f4adf-4ff4-4b93-8225-12c341e41d24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>designation</th>\n",
       "      <th>preprocessed_designation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Olivia: Personalisiertes Notizbuch / 150 Seite...</td>\n",
       "      <td>olivi personalisiert notizbuch 150 seiten punk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Journal Des Arts (Le) N° 133 Du 28/09/2001 - L...</td>\n",
       "      <td>journal art n° 133 28/09/2001 l'art march salo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Grand Stylet Ergonomique Bleu Gamepad Nintendo...</td>\n",
       "      <td>grand stylet ergonom bleu gamepad nintendo wii...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Peluche Donald - Europe - Disneyland 2000 (Mar...</td>\n",
       "      <td>peluch donald europ disneyland 2000 marionnet ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>La Guerre Des Tuques</td>\n",
       "      <td>guerr tuqu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Afrique Contemporaine N° 212 Hiver 2004 - Doss...</td>\n",
       "      <td>afriqu contemporain n° 212 hiv 2004 dossi japon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Christof E: Bildungsprozessen Auf Der Spur</td>\n",
       "      <td>christof e bildungsprozessen auf der spur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Conquérant Sept Cahier Couverture Polypro 240 ...</td>\n",
       "      <td>conquer sept cahi couvertur polypro 240 x 320 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Puzzle Scooby-Doo Avec Poster 2x35 Pieces</td>\n",
       "      <td>puzzl scooby-doo post 2x35 piec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Tente Pliante V3s5-Pro Pvc Blanc - 3 X 4m50 - ...</td>\n",
       "      <td>tent pli v3s5-pro pvc blanc 3 x 4m50 longueur ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         designation  \\\n",
       "0  Olivia: Personalisiertes Notizbuch / 150 Seite...   \n",
       "1  Journal Des Arts (Le) N° 133 Du 28/09/2001 - L...   \n",
       "2  Grand Stylet Ergonomique Bleu Gamepad Nintendo...   \n",
       "3  Peluche Donald - Europe - Disneyland 2000 (Mar...   \n",
       "4                               La Guerre Des Tuques   \n",
       "5  Afrique Contemporaine N° 212 Hiver 2004 - Doss...   \n",
       "6         Christof E: Bildungsprozessen Auf Der Spur   \n",
       "7  Conquérant Sept Cahier Couverture Polypro 240 ...   \n",
       "8          Puzzle Scooby-Doo Avec Poster 2x35 Pieces   \n",
       "9  Tente Pliante V3s5-Pro Pvc Blanc - 3 X 4m50 - ...   \n",
       "\n",
       "                            preprocessed_designation  \n",
       "0  olivi personalisiert notizbuch 150 seiten punk...  \n",
       "1  journal art n° 133 28/09/2001 l'art march salo...  \n",
       "2  grand stylet ergonom bleu gamepad nintendo wii...  \n",
       "3  peluch donald europ disneyland 2000 marionnet ...  \n",
       "4                                         guerr tuqu  \n",
       "5    afriqu contemporain n° 212 hiv 2004 dossi japon  \n",
       "6          christof e bildungsprozessen auf der spur  \n",
       "7  conquer sept cahi couvertur polypro 240 x 320 ...  \n",
       "8                    puzzl scooby-doo post 2x35 piec  \n",
       "9  tent pli v3s5-pro pvc blanc 3 x 4m50 longueur ...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[[\"designation\", \"preprocessed_designation\"]].head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
